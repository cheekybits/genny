package parse

import (
	"bufio"
	"bytes"
	"errors"
	"fmt"
	"go/ast"
	"go/parser"
	"go/scanner"
	"go/token"
	"io"
	"strings"
	"unicode"

	"golang.org/x/tools/imports"
)

var header = []byte(`

// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/cheekybits/genny

`)

var (
	packageKeyword = []byte("package")
	importKeyword  = []byte("import")
	openBrace      = []byte("(")
	closeBrace     = []byte(")")
	genericPackage = "generic"
	genericType    = "generic.Type"
	genericNumber  = "generic.Number"
	linefeed       = "\r\n"
)
var unwantedLinePrefixes = [][]byte{
	[]byte("//go:generate genny "),
}

func subIntoLiteral(lit, typeTemplate, specificType string) string {
	if lit == typeTemplate {
		return specificType
	}
	if !strings.Contains(lit, typeTemplate) {
		return lit
	}
	specificLg := wordify(specificType, true)
	specificSm := wordify(specificType, false)
	result := strings.Replace(lit, typeTemplate, specificLg, -1)
	if strings.HasPrefix(result, specificLg) && !isExported(lit) {
		return strings.Replace(result, specificLg, specificSm, 1)
	}
	return result
}

func subTypeIntoComment(line, typeTemplate, specificType string) string {
	var subbed string
	for _, w := range strings.Fields(line) {
		subbed = subbed + subIntoLiteral(w, typeTemplate, specificType) + " "
	}
	return subbed
}

// Does the heavy lifting of taking a line of our code and
// sbustituting a type into there for our generic type
func subTypeIntoLine(line, typeTemplate, specificType string) string {
	src := []byte(line)
	var s scanner.Scanner
	fset := token.NewFileSet()
	file := fset.AddFile("", fset.Base(), len(src))
	s.Init(file, src, nil, scanner.ScanComments)
	output := ""
	for {
		_, tok, lit := s.Scan()
		if tok == token.EOF {
			break
		} else if tok == token.COMMENT {
			subbed := subTypeIntoComment(lit, typeTemplate, specificType)
			output = output + subbed + " "
		} else if tok.IsLiteral() {
			subbed := subIntoLiteral(lit, typeTemplate, specificType)
			output = output + subbed + " "
		} else {
			output = output + tok.String() + " "
		}
	}
	return output
}

// typeSet looks like "KeyType: int, ValueType: string"
func generateSpecific(filename string, in io.ReadSeeker, typeSet map[string]string) ([]byte, error) {

	// ensure we are at the beginning of the file
	_, err := in.Seek(0, io.SeekStart)
	if err != nil {
		return nil, err
	}

	// parse the source file
	fs := token.NewFileSet()
	file, err := parser.ParseFile(fs, filename, in, 0)
	if err != nil {
		return nil, &errSource{Err: err}
	}

	// make sure every generic.Type is represented in the types
	// argument.
	for _, decl := range file.Decls {
		switch it := decl.(type) {
		case *ast.GenDecl:
			for _, spec := range it.Specs {
				ts, ok := spec.(*ast.TypeSpec)
				if !ok {
					continue
				}
				switch tt := ts.Type.(type) {
				case *ast.SelectorExpr:
					if name, ok := tt.X.(*ast.Ident); ok {
						if name.Name == genericPackage {
							if _, ok := typeSet[ts.Name.Name]; !ok {
								return nil, &errMissingSpecificType{GenericType: ts.Name.Name}
							}
						}
					}
				}
			}
		}
	}

	_, err = in.Seek(0, io.SeekStart)
	if err != nil {
		return nil, err
	}
	var buf bytes.Buffer

	comment := ""
	scanner := bufio.NewScanner(in)
	for scanner.Scan() {

		line := scanner.Text()

		// does this line contain generic.Type?
		if strings.Contains(line, genericType) || strings.Contains(line, genericNumber) {
			comment = ""
			continue
		}

		for t, specificType := range typeSet {
			if strings.Contains(line, t) {
				newLine := subTypeIntoLine(line, t, specificType)
				line = newLine
			}
		}

		if comment != "" {
			buf.WriteString(makeLine(comment))
			comment = ""
		}

		// is this line a comment?
		// TODO: should we handle /* */ comments?
		if strings.HasPrefix(line, "//") {
			// record this line to print later
			comment = line
			continue
		}

		// write the line
		buf.WriteString(makeLine(line))
	}

	// write it out
	return buf.Bytes(), nil
}

// removeFullyQualifiedImportPathAndAddToMap takes a typeset with import paths such as example.com/a/b.MyType and returns a new typeset with b.MyType.
// It adds the package path to the extraPackagesSet, to be later added into the imports section of the generated file.
// It returns the typeSet without package path, or an error if applicable
func removeFullyQualifiedImportPathAndAddToMap(typeSet map[string]string, extraPackagesSet map[string]struct{}) (map[string]string, error) {
	typeSetWithoutFullImportPaths := make(map[string]string)
	for typeName, fullTypePath := range typeSet {
		shortTypePath := fullTypePath
		lastSlashIdx := strings.LastIndex(fullTypePath, "/")
		if lastSlashIdx != -1 {
			// there is a full package name
			lastIdxDot := strings.LastIndex(fullTypePath, ".")
			if lastIdxDot < lastSlashIdx {
				return nil, errors.New("error parsing full package name: last dot index before last slash index")
			}
			extraPackagesSet[fullTypePath[:lastIdxDot]] = struct{}{}
			shortTypePath = fullTypePath[lastSlashIdx+1:]
		}
		typeSetWithoutFullImportPaths[typeName] = shortTypePath
	}

	return typeSetWithoutFullImportPaths, nil
}

// Generics parses the source file and generates the bytes replacing the
// generic types for the keys map with the specific types (its value).
func Generics(filename, outputFilename, pkgName, tag string, in io.ReadSeeker, typeSets []map[string]string) ([]byte, error) {
	var err error
	var localUnwantedLinePrefixes [][]byte
	localUnwantedLinePrefixes = append(localUnwantedLinePrefixes, unwantedLinePrefixes...)

	if tag != "" {
		localUnwantedLinePrefixes = append(localUnwantedLinePrefixes, []byte(fmt.Sprintf("// +build %s", tag)))
	}

	totalOutput := header

	extraPkgsMap := make(map[string]struct{})

	for _, typeSetWithPackagePaths := range typeSets {
		// for each typeset, investigate whether it is a same-package import path (like "User"), or a long import path (like "example.com/a/b.User")
		typeSet, err := removeFullyQualifiedImportPathAndAddToMap(typeSetWithPackagePaths, extraPkgsMap)
		if err != nil {
			return nil, err
		}

		// generate the specifics
		// parsed, err := generateSpecific(filename, in, typeSetWithoutFullImportPaths)
		parsed, err := generateSpecific(filename, in, typeSet)
		if err != nil {
			return nil, err
		}

		totalOutput = append(totalOutput, parsed...)

	}

	// clean up the code line by line
	packageFound := false
	insideImportBlock := false
	var cleanOutputLines []string
	scanner := bufio.NewScanner(bytes.NewReader(totalOutput))
	for scanner.Scan() {

		// end of imports block?
		if insideImportBlock {
			if bytes.HasSuffix(scanner.Bytes(), closeBrace) {
				insideImportBlock = false
			}
			continue
		}

		if bytes.HasPrefix(scanner.Bytes(), packageKeyword) {
			if packageFound {
				continue
			} else {
				packageFound = true
			}
		} else if bytes.HasPrefix(scanner.Bytes(), importKeyword) {
			if bytes.HasSuffix(scanner.Bytes(), openBrace) {
				insideImportBlock = true
			}
			continue
		}

		// check all localUnwantedLinePrefixes - and skip them
		skipline := false
		for _, prefix := range localUnwantedLinePrefixes {
			if bytes.HasPrefix(scanner.Bytes(), prefix) {
				skipline = true
				continue
			}
		}

		if skipline {
			continue
		}

		cleanOutputLines = append(cleanOutputLines, makeLine(scanner.Text()))
	}

	cleanOutput := strings.Join(cleanOutputLines, "")

	output := []byte(cleanOutput)

	// change package name
	if pkgName != "" {
		output = changePackage(bytes.NewReader([]byte(output)), pkgName)
	}
	// fix the imports
	output, err = imports.Process(outputFilename, output, nil)
	if err != nil {
		return nil, &errImports{Err: err}
	}

	var extraPkgs []string
	for importPath := range extraPkgsMap {
		extraPkgs = append(extraPkgs, importPath)
	}

	// add extra imports
	output, err = addExtraImports(bytes.NewReader(output), extraPkgs)
	if err != nil {
		return nil, err
	}

	return output, nil
}

func addExtraImports(in io.ReadSeeker, importPaths []string) ([]byte, error) {
	var outLines []string
	var importBlockProcessed bool

	_, err := in.Seek(0, io.SeekStart)
	if err != nil {
		return nil, err
	}

	var existingImports []string
	var multiLineImportBlockOpen bool
	scanner := bufio.NewScanner(in)
	for scanner.Scan() {
		if importBlockProcessed && !multiLineImportBlockOpen {
			outLines = append(outLines, scanner.Text())
			continue
		}

		if multiLineImportBlockOpen {
			switch scanner.Text() {
			case ")":
				multiLineImportBlockOpen = false
				importBlockProcessed = true
			default:
				existingImports = append(existingImports, scanner.Text())
			}
			continue
		}

		if !strings.HasPrefix(scanner.Text(), "import ") {
			// not the import line. Not interesting to us.
			outLines = append(outLines, scanner.Text())
			continue
		}

		// line is an import declaration. Find out if it is a one or multi line declaration
		if strings.Contains(scanner.Text(), `"`) {
			// one line declaration
			importPath := strings.TrimPrefix(scanner.Text(), "import ")
			existingImports = append(existingImports, fmt.Sprintf("\t%s", importPath))
			importBlockProcessed = true
			continue
		}

		// open multi-line declaration
		multiLineImportBlockOpen = true
	}
	if scanner.Err() != nil {
		return nil, scanner.Err()
	}

	var imports []string
	imports = append(imports, existingImports...)

	for _, importPath := range importPaths {
		// if not already in imports, add to list. Otherwise skip this one
		var isAlreadyInImports bool
		for _, existingImport := range imports {
			if strings.Trim(strings.TrimSpace(existingImport), `"`) == strings.Trim(strings.TrimSpace(importPath), `"`) {
				isAlreadyInImports = true
				break
			}
		}
		if isAlreadyInImports {
			continue
		}
		imports = append(imports, fmt.Sprintf("\t\"%s\"", importPath))
	}

	// add imports
	if len(imports) != 0 {
		var pkgDefProcessed bool

		for i, outLine := range outLines {
			if strings.HasPrefix(outLine, "package ") {
				pkgDefProcessed = true
				continue
			}

			if pkgDefProcessed {
				var importBlock string
				if len(imports) == 1 {
					importBlock = fmt.Sprintf("\nimport %s", strings.TrimPrefix(imports[0], "\t"))
				} else {
					importBlock = fmt.Sprintf("\nimport (\n%s\n)", strings.Join(imports, "\n"))
				}

				if len(existingImports) == 0 {
					// if there were no existing imports, we have to pad the end of the imports line
					importBlock += "\n"
				}
				outLinesPreImport := outLines[:i]
				outLinesPostImport := outLines[i+1:]

				outLines = append(append(outLinesPreImport, importBlock), outLinesPostImport...)
				break
			}
		}
	}

	return []byte(strings.Join(outLines, "\n") + "\n"), nil
}

func makeLine(s string) string {
	return fmt.Sprintln(strings.TrimRight(s, linefeed))
}

// isAlphaNumeric gets whether the rune is alphanumeric or _.
func isAlphaNumeric(r rune) bool {
	return r == '_' || unicode.IsLetter(r) || unicode.IsDigit(r)
}

// wordify turns a type into a nice word for function and type
// names etc.
func wordify(s string, exported bool) string {
	s = strings.TrimRight(s, "{}")
	s = strings.TrimLeft(s, "*&")
	s = strings.Replace(s, ".", "", -1)
	if !exported {
		return s
	}
	return strings.ToUpper(string(s[0])) + s[1:]
}

func changePackage(r io.Reader, pkgName string) []byte {
	var out bytes.Buffer
	sc := bufio.NewScanner(r)
	done := false

	for sc.Scan() {
		s := sc.Text()

		if !done && strings.HasPrefix(s, "package") {
			parts := strings.Split(s, " ")
			parts[1] = pkgName
			s = strings.Join(parts, " ")
			done = true
		}

		fmt.Fprintln(&out, s)
	}
	return out.Bytes()
}

func isExported(lit string) bool {
	if len(lit) == 0 {
		return false
	}
	return unicode.IsUpper(rune(lit[0]))
}
